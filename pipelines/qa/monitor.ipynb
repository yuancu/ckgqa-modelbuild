{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deployment and Monitor\n",
    "\n",
    "This notebook deploy a model trained in pipeline, and monitor it.\n",
    "\n",
    "## Update Model Package Approval Status\n",
    "\n",
    "We can approve the model using the SageMaker Studio UI or programmatically as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from botocore.exceptions import ClientError\n",
    "\n",
    "import os\n",
    "import sagemaker\n",
    "import logging\n",
    "import boto3\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "sm = boto3.Session().client(service_name=\"sagemaker\", region_name=region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_name = 'qa-pipeline-16327098691632709869'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrive Model From Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succeeded\n",
      "[{'PipelineExecutionArn': 'arn:aws:sagemaker:us-east-1:093729152554:pipeline/qa-pipeline-16327098691632709869/execution/jy1d2p7zekky',\n",
      "  'PipelineExecutionDisplayName': 'slot-val-f1-94',\n",
      "  'PipelineExecutionStatus': 'Succeeded',\n",
      "  'StartTime': datetime.datetime(2021, 9, 27, 3, 2, 2, 378000, tzinfo=tzlocal())},\n",
      " {'PipelineExecutionArn': 'arn:aws:sagemaker:us-east-1:093729152554:pipeline/qa-pipeline-16327098691632709869/execution/e1b1hr0ran8z',\n",
      "  'PipelineExecutionDisplayName': 'execution-1632710043206',\n",
      "  'PipelineExecutionStatus': 'Stopped',\n",
      "  'StartTime': datetime.datetime(2021, 9, 27, 2, 34, 3, 47000, tzinfo=tzlocal())},\n",
      " {'PipelineExecutionArn': 'arn:aws:sagemaker:us-east-1:093729152554:pipeline/qa-pipeline-16327098691632709869/execution/yk84zwisygan',\n",
      "  'PipelineExecutionDisplayName': 'execution-1632709950120',\n",
      "  'PipelineExecutionStatus': 'Succeeded',\n",
      "  'StartTime': datetime.datetime(2021, 9, 27, 2, 32, 29, 997000, tzinfo=tzlocal())}]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from pprint import pprint\n",
    "\n",
    "executions_response = sm.list_pipeline_executions(PipelineName=pipeline_name)[\"PipelineExecutionSummaries\"]\n",
    "pipeline_execution_status = executions_response[0][\"PipelineExecutionStatus\"]\n",
    "print(pipeline_execution_status)\n",
    "\n",
    "while pipeline_execution_status == \"Executing\":\n",
    "    try:\n",
    "        executions_response = sm.list_pipeline_executions(PipelineName=pipeline_name)[\"PipelineExecutionSummaries\"]\n",
    "        pipeline_execution_status = executions_response[0][\"PipelineExecutionStatus\"]\n",
    "    #        print('Executions for our pipeline...')\n",
    "    #        print(pipeline_execution_status)\n",
    "    except Exception as e:\n",
    "        print(\"Please wait...\")\n",
    "        time.sleep(30)\n",
    "\n",
    "pprint(executions_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List Execution Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succeeded\n"
     ]
    }
   ],
   "source": [
    "pipeline_execution_status = executions_response[0][\"PipelineExecutionStatus\"]\n",
    "print(pipeline_execution_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:sagemaker:us-east-1:093729152554:pipeline/qa-pipeline-16327098691632709869/execution/jy1d2p7zekky\n"
     ]
    }
   ],
   "source": [
    "pipeline_execution_arn = executions_response[0][\"PipelineExecutionArn\"]\n",
    "print(pipeline_execution_arn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'PipelineExecutionSteps': [{'EndTime': datetime.datetime(2021, 9, 27, 3, 25, 13, 164000, tzinfo=tzlocal()),\n",
      "                             'Metadata': {'RegisterModel': {'Arn': 'arn:aws:sagemaker:us-east-1:093729152554:model-package/qamodelpackagegroup/8'}},\n",
      "                             'StartTime': datetime.datetime(2021, 9, 27, 3, 25, 12, 337000, tzinfo=tzlocal()),\n",
      "                             'StepName': 'QARegisterModel',\n",
      "                             'StepStatus': 'Succeeded'},\n",
      "                            {'EndTime': datetime.datetime(2021, 9, 27, 3, 25, 13, 64000, tzinfo=tzlocal()),\n",
      "                             'Metadata': {'Model': {'Arn': 'arn:aws:sagemaker:us-east-1:093729152554:model/pipelines-jy1d2p7zekky-createqamodel-soa7ikpht4'}},\n",
      "                             'StartTime': datetime.datetime(2021, 9, 27, 3, 25, 12, 267000, tzinfo=tzlocal()),\n",
      "                             'StepName': 'CreateQAModel',\n",
      "                             'StepStatus': 'Succeeded'},\n",
      "                            {'EndTime': datetime.datetime(2021, 9, 27, 3, 25, 11, 814000, tzinfo=tzlocal()),\n",
      "                             'Metadata': {'Condition': {'Outcome': 'True'}},\n",
      "                             'StartTime': datetime.datetime(2021, 9, 27, 3, 25, 11, 27000, tzinfo=tzlocal()),\n",
      "                             'StepName': 'IntentAndSlotCondition',\n",
      "                             'StepStatus': 'Succeeded'},\n",
      "                            {'EndTime': datetime.datetime(2021, 9, 27, 3, 25, 10, 510000, tzinfo=tzlocal()),\n",
      "                             'Metadata': {'ProcessingJob': {'Arn': 'arn:aws:sagemaker:us-east-1:093729152554:processing-job/pipelines-jy1d2p7zekky-evaluatemodel-bv007hps11'}},\n",
      "                             'StartTime': datetime.datetime(2021, 9, 27, 3, 19, 44, 82000, tzinfo=tzlocal()),\n",
      "                             'StepName': 'EvaluateModel',\n",
      "                             'StepStatus': 'Succeeded'},\n",
      "                            {'EndTime': datetime.datetime(2021, 9, 27, 3, 19, 43, 772000, tzinfo=tzlocal()),\n",
      "                             'Metadata': {'TrainingJob': {'Arn': 'arn:aws:sagemaker:us-east-1:093729152554:training-job/pipelines-jy1d2p7zekky-train-xnow7xzq7v'}},\n",
      "                             'StartTime': datetime.datetime(2021, 9, 27, 3, 6, 25, 701000, tzinfo=tzlocal()),\n",
      "                             'StepName': 'Train',\n",
      "                             'StepStatus': 'Succeeded'},\n",
      "                            {'EndTime': datetime.datetime(2021, 9, 27, 3, 6, 24, 980000, tzinfo=tzlocal()),\n",
      "                             'Metadata': {'ProcessingJob': {'Arn': 'arn:aws:sagemaker:us-east-1:093729152554:processing-job/pipelines-jy1d2p7zekky-processing-t8x7f3qjcy'}},\n",
      "                             'StartTime': datetime.datetime(2021, 9, 27, 3, 2, 4, 166000, tzinfo=tzlocal()),\n",
      "                             'StepName': 'Processing',\n",
      "                             'StepStatus': 'Succeeded'}],\n",
      " 'ResponseMetadata': {'HTTPHeaders': {'content-length': '1488',\n",
      "                                      'content-type': 'application/x-amz-json-1.1',\n",
      "                                      'date': 'Mon, 27 Sep 2021 03:29:44 GMT',\n",
      "                                      'x-amzn-requestid': 'c81c3171-5784-4129-8ffb-b1f558dab768'},\n",
      "                      'HTTPStatusCode': 200,\n",
      "                      'RequestId': 'c81c3171-5784-4129-8ffb-b1f558dab768',\n",
      "                      'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "steps = sm.list_pipeline_execution_steps(PipelineExecutionArn=pipeline_execution_arn)\n",
    "\n",
    "pprint(steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Registered Model and Update Model Approval Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:sagemaker:us-east-1:093729152554:model-package/qamodelpackagegroup/8\n"
     ]
    }
   ],
   "source": [
    "for execution_step in steps[\"PipelineExecutionSteps\"]:\n",
    "    if execution_step[\"StepName\"] == \"QARegisterModel\":\n",
    "        model_package_arn = execution_step[\"Metadata\"][\"RegisterModel\"][\"Arn\"]\n",
    "        break\n",
    "print(model_package_arn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_package_update_response = sm.update_model_package(\n",
    "    ModelPackageArn=model_package_arn,\n",
    "    ModelApprovalStatus=\"Approved\",  # Other options are Rejected and PendingManualApproval\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Created Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:sagemaker:us-east-1:093729152554:model/pipelines-jy1d2p7zekky-createqamodel-soa7ikpht4\n",
      "created_model_name: pipelines-jy1d2p7zekky-createqamodel-soa7ikpht4\n"
     ]
    }
   ],
   "source": [
    "for execution_step in steps[\"PipelineExecutionSteps\"]:\n",
    "    if execution_step[\"StepName\"] == \"CreateQAModel\":\n",
    "        model_arn = execution_step[\"Metadata\"][\"Model\"][\"Arn\"]\n",
    "        break\n",
    "print(model_arn)\n",
    "\n",
    "created_model_name = model_arn.split(\"/\")[-1]\n",
    "print('created_model_name:', created_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model Endpoint from Model Registry and Configure It to Capture Requests\n",
    "\n",
    "### Create model from registry\n",
    "\n",
    "More details here: https://docs.aws.amazon.com/sagemaker/latest/dg/model-registry-deploy.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model from registry name : qa-model-from-registry-1632713407\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "timestamp = int(time.time())\n",
    "\n",
    "model_from_registry_name = \"qa-model-from-registry-{}\".format(timestamp)\n",
    "print(\"Model from registry name : {}\".format(model_from_registry_name))\n",
    "\n",
    "model_registry_package_container = {\n",
    "    \"ModelPackageName\": model_package_arn,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ModelArn': 'arn:aws:sagemaker:us-east-1:093729152554:model/qa-model-from-registry-1632713407',\n",
      " 'ResponseMetadata': {'HTTPHeaders': {'content-length': '95',\n",
      "                                      'content-type': 'application/x-amz-json-1.1',\n",
      "                                      'date': 'Mon, 27 Sep 2021 03:30:09 GMT',\n",
      "                                      'x-amzn-requestid': '8b88949f-93c7-4917-8585-527be5e99b10'},\n",
      "                      'HTTPStatusCode': 200,\n",
      "                      'RequestId': '8b88949f-93c7-4917-8585-527be5e99b10',\n",
      "                      'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "create_model_from_registry_respose = sm.create_model(\n",
    "    ModelName=model_from_registry_name, ExecutionRoleArn=role, PrimaryContainer=model_registry_package_container\n",
    ")\n",
    "pprint(create_model_from_registry_respose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arn:aws:sagemaker:us-east-1:093729152554:model/qa-model-from-registry-1632713407'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_from_registry_arn = create_model_from_registry_respose[\"ModelArn\"]\n",
    "model_from_registry_arn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Endpoint to Capture Data from Requests and Responses\n",
    "\n",
    "Check API for [create_endpoint_config](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sagemaker.html#SageMaker.Client.create_endpoint_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_capture_bucket = 'sm-nlp-data'\n",
    "data_capture_prefix = 'inference/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates an endpoint configuration that Amazon SageMaker hosting services uses to deploy models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qa-model-from-registry-epc-1632713407\n"
     ]
    }
   ],
   "source": [
    "endpoint_config_name = \"qa-model-from-registry-epc-{}\".format(timestamp)\n",
    "print(endpoint_config_name)\n",
    "\n",
    "create_endpoint_config_response = sm.create_endpoint_config(\n",
    "    EndpointConfigName=endpoint_config_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"InstanceType\": \"ml.m5.4xlarge\",\n",
    "            \"InitialVariantWeight\": 1,\n",
    "            \"InitialInstanceCount\": 1,\n",
    "            \"ModelName\": created_model_name,\n",
    "            \"VariantName\": \"AllTraffic\",\n",
    "        }\n",
    "    ],\n",
    "    DataCaptureConfig={\n",
    "        'EnableCapture': True,\n",
    "        'InitialSamplingPercentage': 100,\n",
    "        'DestinationS3Uri': f\"s3://{data_capture_bucket}/{data_capture_prefix}\",\n",
    "        'CaptureOptions': [\n",
    "            {\n",
    "                'CaptureMode': 'Input'\n",
    "            },\n",
    "            {\n",
    "                'CaptureMode': 'Output'\n",
    "            },\n",
    "        ]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "delete an existing config with the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !aws sagemaker delete-endpoint-config --endpoint-config-name $endpoint_config_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EndpointName=qa-model-from-registry-ep-1632713407\n",
      "arn:aws:sagemaker:us-east-1:093729152554:endpoint/qa-model-from-registry-ep-1632713407\n"
     ]
    }
   ],
   "source": [
    "pipeline_endpoint_name = \"qa-model-from-registry-ep-{}\".format(timestamp)\n",
    "print(\"EndpointName={}\".format(pipeline_endpoint_name))\n",
    "\n",
    "create_endpoint_response = sm.create_endpoint(\n",
    "    EndpointName=pipeline_endpoint_name, EndpointConfigName=endpoint_config_name\n",
    ")\n",
    "print(create_endpoint_response[\"EndpointArn\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>Review <a target=\"blank\" href=\"https://console.aws.amazon.com/sagemaker/home?region=us-east-1#/endpoints/qa-model-from-registry-ep-1632713407\">SageMaker REST Endpoint</a></b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(\n",
    "    HTML(\n",
    "        '<b>Review <a target=\"blank\" href=\"https://console.aws.amazon.com/sagemaker/home?region={}#/endpoints/{}\">SageMaker REST Endpoint</a></b>'.format(\n",
    "            region, pipeline_endpoint_name\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 182 ms, sys: 19.2 ms, total: 202 ms\n",
      "Wall time: 8min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "waiter = sm.get_waiter(\"endpoint_in_service\")\n",
    "waiter.wait(EndpointName=pipeline_endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List All Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'StepName': 'Processing', 'StartTime': datetime.datetime(2021, 9, 27, 3, 2, 4, 166000, tzinfo=tzlocal()), 'EndTime': datetime.datetime(2021, 9, 27, 3, 6, 24, 980000, tzinfo=tzlocal()), 'StepStatus': 'Succeeded', 'Metadata': {'ProcessingJob': {'Arn': 'arn:aws:sagemaker:us-east-1:093729152554:processing-job/pipelines-jy1d2p7zekky-processing-t8x7f3qjcy'}}}\n",
      "pipelines-jy1d2p7zekky-processing-t8x7f3qjcy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name/Source</th>\n",
       "      <th>Direction</th>\n",
       "      <th>Type</th>\n",
       "      <th>Association Type</th>\n",
       "      <th>Lineage Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s3://...27-02-33-20-926/input/code/preprocess.py</td>\n",
       "      <td>Input</td>\n",
       "      <td>DataSet</td>\n",
       "      <td>ContributedTo</td>\n",
       "      <td>artifact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s3://sm-nlp-data/nlu/data/qa_raw.zip</td>\n",
       "      <td>Input</td>\n",
       "      <td>DataSet</td>\n",
       "      <td>ContributedTo</td>\n",
       "      <td>artifact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>68331...om/sagemaker-scikit-learn:0.23-1-cpu-py3</td>\n",
       "      <td>Input</td>\n",
       "      <td>Image</td>\n",
       "      <td>ContributedTo</td>\n",
       "      <td>artifact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s3://sm-nlp-data/nlu/data/processed/</td>\n",
       "      <td>Output</td>\n",
       "      <td>DataSet</td>\n",
       "      <td>Produced</td>\n",
       "      <td>artifact</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Name/Source Direction     Type  \\\n",
       "0  s3://...27-02-33-20-926/input/code/preprocess.py     Input  DataSet   \n",
       "1              s3://sm-nlp-data/nlu/data/qa_raw.zip     Input  DataSet   \n",
       "2  68331...om/sagemaker-scikit-learn:0.23-1-cpu-py3     Input    Image   \n",
       "3              s3://sm-nlp-data/nlu/data/processed/    Output  DataSet   \n",
       "\n",
       "  Association Type Lineage Type  \n",
       "0    ContributedTo     artifact  \n",
       "1    ContributedTo     artifact  \n",
       "2    ContributedTo     artifact  \n",
       "3         Produced     artifact  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'StepName': 'Train', 'StartTime': datetime.datetime(2021, 9, 27, 3, 6, 25, 701000, tzinfo=tzlocal()), 'EndTime': datetime.datetime(2021, 9, 27, 3, 19, 43, 772000, tzinfo=tzlocal()), 'StepStatus': 'Succeeded', 'Metadata': {'TrainingJob': {'Arn': 'arn:aws:sagemaker:us-east-1:093729152554:training-job/pipelines-jy1d2p7zekky-train-xnow7xzq7v'}}}\n",
      "pipelines-jy1d2p7zekky-train-xnow7xzq7v\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name/Source</th>\n",
       "      <th>Direction</th>\n",
       "      <th>Type</th>\n",
       "      <th>Association Type</th>\n",
       "      <th>Lineage Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s3://sm-nlp-data/nlu/data/processed/</td>\n",
       "      <td>Input</td>\n",
       "      <td>DataSet</td>\n",
       "      <td>ContributedTo</td>\n",
       "      <td>artifact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76310...onaws.com/pytorch-training:1.8.1-gpu-py3</td>\n",
       "      <td>Input</td>\n",
       "      <td>Image</td>\n",
       "      <td>ContributedTo</td>\n",
       "      <td>artifact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s3://...kky-Train-XNow7xzQ7v/output/model.tar.gz</td>\n",
       "      <td>Output</td>\n",
       "      <td>Model</td>\n",
       "      <td>Produced</td>\n",
       "      <td>artifact</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Name/Source Direction     Type  \\\n",
       "0              s3://sm-nlp-data/nlu/data/processed/     Input  DataSet   \n",
       "1  76310...onaws.com/pytorch-training:1.8.1-gpu-py3     Input    Image   \n",
       "2  s3://...kky-Train-XNow7xzQ7v/output/model.tar.gz    Output    Model   \n",
       "\n",
       "  Association Type Lineage Type  \n",
       "0    ContributedTo     artifact  \n",
       "1    ContributedTo     artifact  \n",
       "2         Produced     artifact  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'StepName': 'EvaluateModel', 'StartTime': datetime.datetime(2021, 9, 27, 3, 19, 44, 82000, tzinfo=tzlocal()), 'EndTime': datetime.datetime(2021, 9, 27, 3, 25, 10, 510000, tzinfo=tzlocal()), 'StepStatus': 'Succeeded', 'Metadata': {'ProcessingJob': {'Arn': 'arn:aws:sagemaker:us-east-1:093729152554:processing-job/pipelines-jy1d2p7zekky-evaluatemodel-bv007hps11'}}}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name/Source</th>\n",
       "      <th>Direction</th>\n",
       "      <th>Type</th>\n",
       "      <th>Association Type</th>\n",
       "      <th>Lineage Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s3://...9-27-02-34-02-425/input/code/evaluate.py</td>\n",
       "      <td>Input</td>\n",
       "      <td>DataSet</td>\n",
       "      <td>ContributedTo</td>\n",
       "      <td>artifact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s3://sm-nlp-data/nlu/data/processed/</td>\n",
       "      <td>Input</td>\n",
       "      <td>DataSet</td>\n",
       "      <td>ContributedTo</td>\n",
       "      <td>artifact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s3://...kky-Train-XNow7xzQ7v/output/model.tar.gz</td>\n",
       "      <td>Input</td>\n",
       "      <td>Model</td>\n",
       "      <td>ContributedTo</td>\n",
       "      <td>artifact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>68331...om/sagemaker-scikit-learn:0.23-1-cpu-py3</td>\n",
       "      <td>Input</td>\n",
       "      <td>Image</td>\n",
       "      <td>ContributedTo</td>\n",
       "      <td>artifact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s3://...n-2021-09-27-02-31-10-102/output/metrics</td>\n",
       "      <td>Output</td>\n",
       "      <td>DataSet</td>\n",
       "      <td>Produced</td>\n",
       "      <td>artifact</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Name/Source Direction     Type  \\\n",
       "0  s3://...9-27-02-34-02-425/input/code/evaluate.py     Input  DataSet   \n",
       "1              s3://sm-nlp-data/nlu/data/processed/     Input  DataSet   \n",
       "2  s3://...kky-Train-XNow7xzQ7v/output/model.tar.gz     Input    Model   \n",
       "3  68331...om/sagemaker-scikit-learn:0.23-1-cpu-py3     Input    Image   \n",
       "4  s3://...n-2021-09-27-02-31-10-102/output/metrics    Output  DataSet   \n",
       "\n",
       "  Association Type Lineage Type  \n",
       "0    ContributedTo     artifact  \n",
       "1    ContributedTo     artifact  \n",
       "2    ContributedTo     artifact  \n",
       "3    ContributedTo     artifact  \n",
       "4         Produced     artifact  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'StepName': 'IntentAndSlotCondition', 'StartTime': datetime.datetime(2021, 9, 27, 3, 25, 11, 27000, tzinfo=tzlocal()), 'EndTime': datetime.datetime(2021, 9, 27, 3, 25, 11, 814000, tzinfo=tzlocal()), 'StepStatus': 'Succeeded', 'Metadata': {'Condition': {'Outcome': 'True'}}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'StepName': 'CreateQAModel', 'StartTime': datetime.datetime(2021, 9, 27, 3, 25, 12, 267000, tzinfo=tzlocal()), 'EndTime': datetime.datetime(2021, 9, 27, 3, 25, 13, 64000, tzinfo=tzlocal()), 'StepStatus': 'Succeeded', 'Metadata': {'Model': {'Arn': 'arn:aws:sagemaker:us-east-1:093729152554:model/pipelines-jy1d2p7zekky-createqamodel-soa7ikpht4'}}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'StepName': 'QARegisterModel', 'StartTime': datetime.datetime(2021, 9, 27, 3, 25, 12, 337000, tzinfo=tzlocal()), 'EndTime': datetime.datetime(2021, 9, 27, 3, 25, 13, 164000, tzinfo=tzlocal()), 'StepStatus': 'Succeeded', 'Metadata': {'RegisterModel': {'Arn': 'arn:aws:sagemaker:us-east-1:093729152554:model-package/qamodelpackagegroup/8'}}}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name/Source</th>\n",
       "      <th>Direction</th>\n",
       "      <th>Type</th>\n",
       "      <th>Association Type</th>\n",
       "      <th>Lineage Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>qamodelpackagegroup-8-Approved-1632713391-aws-...</td>\n",
       "      <td>Input</td>\n",
       "      <td>Approval</td>\n",
       "      <td>ContributedTo</td>\n",
       "      <td>action</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s3://...kky-Train-XNow7xzQ7v/output/model.tar.gz</td>\n",
       "      <td>Input</td>\n",
       "      <td>Model</td>\n",
       "      <td>ContributedTo</td>\n",
       "      <td>artifact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76310...naws.com/pytorch-inference:1.8.1-gpu-py3</td>\n",
       "      <td>Input</td>\n",
       "      <td>Image</td>\n",
       "      <td>ContributedTo</td>\n",
       "      <td>artifact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>qamodelpackagegroup-8-PendingManualApproval-16...</td>\n",
       "      <td>Input</td>\n",
       "      <td>Approval</td>\n",
       "      <td>ContributedTo</td>\n",
       "      <td>action</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>QAModelPackageGroup-1631002331-aws-model-packa...</td>\n",
       "      <td>Output</td>\n",
       "      <td>ModelGroup</td>\n",
       "      <td>AssociatedWith</td>\n",
       "      <td>context</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Name/Source Direction        Type  \\\n",
       "0  qamodelpackagegroup-8-Approved-1632713391-aws-...     Input    Approval   \n",
       "1   s3://...kky-Train-XNow7xzQ7v/output/model.tar.gz     Input       Model   \n",
       "2   76310...naws.com/pytorch-inference:1.8.1-gpu-py3     Input       Image   \n",
       "3  qamodelpackagegroup-8-PendingManualApproval-16...     Input    Approval   \n",
       "4  QAModelPackageGroup-1631002331-aws-model-packa...    Output  ModelGroup   \n",
       "\n",
       "  Association Type Lineage Type  \n",
       "0    ContributedTo       action  \n",
       "1    ContributedTo     artifact  \n",
       "2    ContributedTo     artifact  \n",
       "3    ContributedTo       action  \n",
       "4   AssociatedWith      context  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "from sagemaker.lineage.visualizer import LineageTableVisualizer\n",
    "\n",
    "viz = LineageTableVisualizer(sagemaker.session.Session())\n",
    "\n",
    "for execution_step in reversed(steps[\"PipelineExecutionSteps\"]):\n",
    "    print(execution_step)\n",
    "    # We are doing this because there appears to be a bug of this LineageTableVisualizer handling the Processing Step\n",
    "    if execution_step[\"StepName\"] == \"Processing\":\n",
    "        processing_job_name = execution_step[\"Metadata\"][\"ProcessingJob\"][\"Arn\"].split(\"/\")[-1]\n",
    "        print(processing_job_name)\n",
    "        display(viz.show(processing_job_name=processing_job_name))\n",
    "    elif execution_step[\"StepName\"] == \"Train\":\n",
    "        training_job_name = execution_step[\"Metadata\"][\"TrainingJob\"][\"Arn\"].split(\"/\")[-1]\n",
    "        print(training_job_name)\n",
    "        display(viz.show(training_job_name=training_job_name))\n",
    "    else:\n",
    "        display(viz.show(pipeline_execution_step=execution_step))\n",
    "        time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Deployed Model\n",
    "\n",
    "CSVSerializer: [DOC](https://sagemaker.readthedocs.io/en/stable/api/inference/serializers.html#sagemaker.serializers.CSVSerializer) </br>\n",
    "JSONDeserializer: [DOC](https://sagemaker.readthedocs.io/en/stable/api/inference/deserializers.html#sagemaker.deserializers.JSONDeserializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sagemaker.pytorch.model import PyTorchPredictor\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "predictor = PyTorchPredictor(\n",
    "    endpoint_name=pipeline_endpoint_name,\n",
    "    sagemaker_session=sess,\n",
    "    serializer=CSVSerializer(),\n",
    "    deserializer=JSONDeserializer(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try predict on some sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': [['伊', '坂', '幸', '太', '郎', '写', '了', '哪', '些', '书'],\n",
       "  ['O',\n",
       "   'N',\n",
       "   'E',\n",
       "   ' ',\n",
       "   'P',\n",
       "   'I',\n",
       "   'E',\n",
       "   'C',\n",
       "   'E',\n",
       "   '総',\n",
       "   '集',\n",
       "   '编',\n",
       "   ' ',\n",
       "   'T',\n",
       "   'H',\n",
       "   'E',\n",
       "   ' ',\n",
       "   'F',\n",
       "   'I',\n",
       "   'R',\n",
       "   'S',\n",
       "   'T',\n",
       "   ' ',\n",
       "   'L',\n",
       "   'O',\n",
       "   'G',\n",
       "   '是',\n",
       "   '谁',\n",
       "   '写',\n",
       "   '的'],\n",
       "  ['高',\n",
       "   '效',\n",
       "   '管',\n",
       "   '理',\n",
       "   'W',\n",
       "   'i',\n",
       "   'n',\n",
       "   'd',\n",
       "   'o',\n",
       "   'w',\n",
       "   's',\n",
       "   '网',\n",
       "   '络',\n",
       "   '/',\n",
       "   'W',\n",
       "   'i',\n",
       "   'n',\n",
       "   '3',\n",
       "   '2',\n",
       "   ' ',\n",
       "   'P',\n",
       "   'e',\n",
       "   'r',\n",
       "   'l',\n",
       "   '应',\n",
       "   '用',\n",
       "   '之',\n",
       "   '道',\n",
       "   '的',\n",
       "   '作',\n",
       "   '者',\n",
       "   '是',\n",
       "   '谁'],\n",
       "  ['D', 'a', 'v', 'e', '写', '了', '什', '么', '书'],\n",
       "  ['洪', '荒', '之', '武', '道', '是', '谁', '写', '的'],\n",
       "  ['玄', '黄', '真', '人', '写', '了', '哪', '些', '书'],\n",
       "  ['风', '景', '景', '观', '工', '程', '体', '系', '化', '是', '谁', '的', '作', '品'],\n",
       "  ['微', '知', '汇', '：', '万', '物', '简', '史', '的', '作', '者', '是', '谁'],\n",
       "  ['孽', '阳', '的', '作', '者', '是', '谁'],\n",
       "  ['茅', '月', '写', '了', '哪', '些', '书'],\n",
       "  ['未', '来', '娱', '乐', '系', '统', '是', '谁', '写', '的'],\n",
       "  ['小', '僧', '不', '敲', '木', '鱼', '有', '什', '么', '著', '作'],\n",
       "  ['金', '装', '四', '大', '才', '子', '是', '谁', '的', '作', '品'],\n",
       "  ['罗', '永', '贤', '导', '演', '了', '哪', '些', '电', '影'],\n",
       "  ['为',\n",
       "   '了',\n",
       "   '你',\n",
       "   '我',\n",
       "   '愿',\n",
       "   '意',\n",
       "   '热',\n",
       "   '爱',\n",
       "   '整',\n",
       "   '个',\n",
       "   '世',\n",
       "   '界',\n",
       "   '是',\n",
       "   '谁',\n",
       "   '的',\n",
       "   '作',\n",
       "   '品'],\n",
       "  ['郭', '虎', '导', '演', '了', '哪', '些', '电', '影'],\n",
       "  ['为',\n",
       "   '了',\n",
       "   '你',\n",
       "   '我',\n",
       "   '愿',\n",
       "   '意',\n",
       "   '热',\n",
       "   '爱',\n",
       "   '整',\n",
       "   '个',\n",
       "   '世',\n",
       "   '界',\n",
       "   '是',\n",
       "   '谁',\n",
       "   '导',\n",
       "   '演',\n",
       "   '的'],\n",
       "  ['灭', '罪', '师', '的', '导', '演', '是', '谁'],\n",
       "  ['杨', '苗', '导', '演', '了', '哪', '些', '电', '视', '剧'],\n",
       "  ['灭', '罪', '师', '是', '谁', '导', '演', '的'],\n",
       "  ['五', '百', '导', '演', '了', '哪', '些', '电', '视', '剧'],\n",
       "  ['穆', '念', '慈', '的', '丈', '夫', '是', '谁'],\n",
       "  ['杨', '康', '的', '配', '偶', '是', '谁']],\n",
       " 'intentions': ['ask_books',\n",
       "  'ask_author',\n",
       "  'ask_author',\n",
       "  'ask_books',\n",
       "  'ask_author',\n",
       "  'ask_books',\n",
       "  'ask_author',\n",
       "  'ask_author',\n",
       "  'ask_author',\n",
       "  'ask_books',\n",
       "  'ask_author',\n",
       "  'ask_books',\n",
       "  'ask_author',\n",
       "  'ask_films',\n",
       "  'ask_author',\n",
       "  'ask_films',\n",
       "  'ask_director',\n",
       "  'ask_director',\n",
       "  'ask_films',\n",
       "  'ask_director',\n",
       "  'ask_films',\n",
       "  'ask_husband',\n",
       "  'ask_husband'],\n",
       " 'slot_labels': [['B_name',\n",
       "   'I_name',\n",
       "   'I_name',\n",
       "   'I_name',\n",
       "   'I_name',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O'],\n",
       "  ['B_book',\n",
       "   'I_book',\n",
       "   'I_book',\n",
       "   'I_book',\n",
       "   'I_book',\n",
       "   'I_book',\n",
       "   'I_book',\n",
       "   'I_book',\n",
       "   'I_book',\n",
       "   'I_book',\n",
       "   'I_book',\n",
       "   'I_book',\n",
       "   'I_book',\n",
       "   'I_book',\n",
       "   'I_book',\n",
       "   'I_book',\n",
       "   'I_book',\n",
       "   'I_book',\n",
       "   'I_book',\n",
       "   'I_book',\n",
       "   'I_book',\n",
       "   'I_book',\n",
       "   'I_book',\n",
       "   'I_book',\n",
       "   'I_book',\n",
       "   'I_book',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O'],\n",
       "  ['B_book',\n",
       "   'I_book',\n",
       "   'I_book',\n",
       "   'I_book',\n",
       "   'I_book',\n",
       "   'I_book',\n",
       "   'I_book',\n",
       "   'I_book',\n",
       "   'I_book',\n",
       "   'I_book',\n",
       "   'I_book',\n",
       "   'I_book',\n",
       "   'I_book',\n",
       "   'I_book',\n",
       "   'I_book',\n",
       "   'I_book',\n",
       "   'I_book',\n",
       "   'I_book',\n",
       "   'I_book',\n",
       "   'I_book',\n",
       "   'I_book',\n",
       "   'I_book',\n",
       "   'I_book',\n",
       "   'I_book',\n",
       "   'I_book',\n",
       "   'I_book',\n",
       "   'I_book',\n",
       "   'I_book',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O'],\n",
       "  ['B_name', 'I_name', 'I_name', 'I_name', 'O', 'O', 'O', 'O', 'O'],\n",
       "  ['B_book', 'I_book', 'I_book', 'I_book', 'I_book', 'O', 'O', 'O', 'O'],\n",
       "  ['B_name', 'I_name', 'I_name', 'I_name', 'O', 'O', 'O', 'O', 'O'],\n",
       "  ['B_book',\n",
       "   'I_book',\n",
       "   'I_book',\n",
       "   'I_book',\n",
       "   'I_book',\n",
       "   'I_book',\n",
       "   'I_book',\n",
       "   'I_book',\n",
       "   'I_book',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O'],\n",
       "  ['B_book',\n",
       "   'I_book',\n",
       "   'I_book',\n",
       "   'I_book',\n",
       "   'I_book',\n",
       "   'I_book',\n",
       "   'I_book',\n",
       "   'I_book',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O'],\n",
       "  ['B_book', 'I_book', 'O', 'O', 'O', 'O', 'O'],\n",
       "  ['B_name', 'I_name', 'O', 'O', 'O', 'O', 'O'],\n",
       "  ['B_book',\n",
       "   'I_book',\n",
       "   'I_book',\n",
       "   'I_book',\n",
       "   'I_book',\n",
       "   'I_book',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O'],\n",
       "  ['B_name',\n",
       "   'I_name',\n",
       "   'I_name',\n",
       "   'I_name',\n",
       "   'I_name',\n",
       "   'I_name',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O'],\n",
       "  ['B_book',\n",
       "   'I_book',\n",
       "   'I_book',\n",
       "   'I_book',\n",
       "   'I_book',\n",
       "   'I_book',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O'],\n",
       "  ['B_name', 'I_name', 'I_name', 'O', 'O', 'O', 'O', 'O', 'O', 'O'],\n",
       "  ['B_book',\n",
       "   'I_book',\n",
       "   'I_book',\n",
       "   'I_book',\n",
       "   'I_book',\n",
       "   'I_book',\n",
       "   'I_book',\n",
       "   'I_book',\n",
       "   'I_book',\n",
       "   'I_book',\n",
       "   'I_book',\n",
       "   'I_book',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O'],\n",
       "  ['B_name', 'I_name', 'O', 'O', 'O', 'O', 'O', 'O', 'O'],\n",
       "  ['B_film',\n",
       "   'I_film',\n",
       "   'I_film',\n",
       "   'I_film',\n",
       "   'I_film',\n",
       "   'I_film',\n",
       "   'I_film',\n",
       "   'I_film',\n",
       "   'I_film',\n",
       "   'I_film',\n",
       "   'I_film',\n",
       "   'I_film',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O'],\n",
       "  ['B_film', 'I_film', 'I_film', 'O', 'O', 'O', 'O', 'O'],\n",
       "  ['B_name', 'I_name', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'],\n",
       "  ['B_film', 'I_film', 'I_film', 'O', 'O', 'O', 'O', 'O'],\n",
       "  ['B_name', 'I_name', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'],\n",
       "  ['B_name', 'I_name', 'I_name', 'O', 'O', 'O', 'O', 'O'],\n",
       "  ['B_name', 'I_name', 'O', 'O', 'O', 'O', 'O']]}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('processed/psuedo/seq.in', 'r') as f:\n",
    "    lines = f.read()\n",
    "    predicted = predictor.predict(lines)\n",
    "predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would be too long and go out of wait limitation if we predict all the data all at once, so we split them into little chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:55<00:00,  3.08s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "chunk_size = 20\n",
    "predicted_cls = []\n",
    "with open('processed/test/seq.in') as f:\n",
    "    lines = f.readlines()\n",
    "    chunks = [lines[i: i+chunk_size] for i in range(0, len(lines), chunk_size)]\n",
    "    for chunk in tqdm(chunks):\n",
    "        predicted = predictor.predict(chunk)\n",
    "        predicted_cls += predicted['intentions']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Captured Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Capture Files:\n",
      "inference/qa-model-from-registry-ep-1632713407/AllTraffic/2021/09/27/03/46-40-392-89950adc-6ce6-4662-856c-c64f47b2c15f.jsonl\n"
     ]
    }
   ],
   "source": [
    "s3 = boto3.Session().client('s3')\n",
    "current_endpoint_capture_prefix = '{}{}'.format(data_capture_prefix, pipeline_endpoint_name)\n",
    "result = s3.list_objects(Bucket=data_capture_bucket, Prefix=current_endpoint_capture_prefix)\n",
    "capture_files = [capture_file.get(\"Key\") for capture_file in result.get('Contents')]\n",
    "print(\"Found Capture Files:\")\n",
    "print(\"\\n \".join(capture_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'inference/qa-model-from-registry-ep-1632713407/AllTraffic/2021/09/27/03/46-40-392-89950adc-6ce6-4662-856c-c64f47b2c15f.jsonl'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "capture_files[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use the S3Downloader utility to view and download the captured data in Amazon S3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.s3 import S3Downloader\n",
    "traffic = S3Downloader.read_file(f\"s3://{data_capture_bucket}/{capture_files[0]}\")\n",
    "traffic[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_i = traffic.strip().split('\\n')[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_input_data = json.loads(traffic_i)['captureData']['endpointInput']['data']\n",
    "endpoint_output_data = json.loads(traffic_i)['captureData']['endpointOutput']['data']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decode payload with base64 library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'有哪些人从中国人民大学毕业\\n\\n将爱情进行到底是谁导演的\\n\\n超品神医是谁写的\\n\\n冰林写了哪些书\\n\\n王锋的国籍是什么\\n\\n王锋从哪里毕业\\n\\n有哪些人从北京大学毕业\\n\\n谁写了东坡易传\\n\\n王现昌的国籍是什么\\n\\n赏金猎人的导演是谁\\n\\n鲁斯达是哪个国家的人\\n\\n布拉德·皮特的妻子是谁\\n\\n安吉丽娜·朱莉的配偶是谁\\n\\n铁马战车是谁的作品\\n\\n天才宝贝恶魔冤家的作者是谁\\n\\n空白丶写了什么书\\n\\n江南逢李龟年是谁写的\\n\\n异界之再战风云是谁的作品\\n\\n品味人生写了什么书\\n\\n看透你的作者是谁\\n'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import base64\n",
    "\n",
    "base64.b64decode(endpoint_input_data).decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"text\": [[\"有\", \"哪\", \"些\", \"人\", \"从\", \"中\", \"国\", \"人\", \"民\", \"大\", \"学\", \"毕\", \"业\"], [\"将\", \"爱\", \"情\", \"进\", \"行\", \"到\", \"底\", \"是\", \"谁\", \"导\", \"演\", \"的\"], [\"超\", \"品\", \"神\", \"医\", \"是\", \"谁\", \"写\", \"的\"], [\"冰\", \"林\", \"写\", \"了\", \"哪\", \"些\", \"书\"], [\"王\", \"锋\", \"的\", \"国\", \"籍\", \"是\", \"什\", \"么\"], [\"王\", \"锋\", \"从\", \"哪\", \"里\", \"毕\", \"业\"], [\"有\", \"哪\", \"些\", \"人\", \"从\", \"北\", \"京\", \"大\", \"学\", \"毕\", \"业\"], [\"谁\", \"写\", \"了\", \"东\", \"坡\", \"易\", \"传\"], [\"王\", \"现\", \"昌\", \"的\", \"国\", \"籍\", \"是\", \"什\", \"么\"], [\"赏\", \"金\", \"猎\", \"人\", \"的\", \"导\", \"演\", \"是\", \"谁\"], [\"鲁\", \"斯\", \"达\", \"是\", \"哪\", \"个\", \"国\", \"家\", \"的\", \"人\"], [\"布\", \"拉\", \"德\", \"·\", \"皮\", \"特\", \"的\", \"妻\", \"子\", \"是\", \"谁\"], [\"安\", \"吉\", \"丽\", \"娜\", \"·\", \"朱\", \"莉\", \"的\", \"配\", \"偶\", \"是\", \"谁\"], [\"铁\", \"马\", \"战\", \"车\", \"是\", \"谁\", \"的\", \"作\", \"品\"], [\"天\", \"才\", \"宝\", \"贝\", \"恶\", \"魔\", \"冤\", \"家\", \"的\", \"作\", \"者\", \"是\", \"谁\"], [\"空\", \"白\", \"丶\", \"写\", \"了\", \"什\", \"么\", \"书\"], [\"江\", \"南\", \"逢\", \"李\", \"龟\", \"年\", \"是\", \"谁\", \"写\", \"的\"], [\"异\", \"界\", \"之\", \"再\", \"战\", \"风\", \"云\", \"是\", \"谁\", \"的\", \"作\", \"品\"], [\"品\", \"味\", \"人\", \"生\", \"写\", \"了\", \"什\", \"么\", \"书\"], [\"看\", \"透\", \"你\", \"的\", \"作\", \"者\", \"是\", \"谁\"]], \"intentions\": [\"ask_alumni\", \"ask_director\", \"ask_author\", \"ask_books\", \"ask_nationality\", \"ask_school\", \"ask_alumni\", \"ask_author\", \"ask_nationality\", \"ask_director\", \"ask_nationality\", \"ask_wife\", \"ask_husband\", \"ask_director\", \"ask_author\", \"ask_books\", \"ask_author\", \"ask_author\", \"ask_books\", \"ask_author\"], \"slot_labels\": [[\"O\", \"O\", \"O\", \"O\", \"O\", \"B_school\", \"I_school\", \"I_school\", \"I_school\", \"I_school\", \"I_school\", \"O\", \"O\"], [\"B_film\", \"I_film\", \"I_film\", \"I_film\", \"I_film\", \"I_film\", \"I_film\", \"O\", \"O\", \"O\", \"O\", \"O\"], [\"B_book\", \"I_book\", \"I_book\", \"I_book\", \"O\", \"O\", \"O\", \"O\"], [\"B_name\", \"I_name\", \"O\", \"O\", \"O\", \"O\", \"O\"], [\"B_name\", \"I_name\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"], [\"B_name\", \"I_name\", \"O\", \"O\", \"O\", \"O\", \"O\"], [\"O\", \"O\", \"O\", \"O\", \"O\", \"B_school\", \"I_school\", \"I_school\", \"I_school\", \"O\", \"O\"], [\"O\", \"O\", \"O\", \"B_book\", \"I_book\", \"I_book\", \"I_book\"], [\"B_name\", \"I_name\", \"I_name\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"], [\"B_film\", \"I_film\", \"I_film\", \"I_film\", \"O\", \"O\", \"O\", \"O\", \"O\"], [\"B_name\", \"I_name\", \"I_name\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"], [\"B_name\", \"I_name\", \"I_name\", \"I_name\", \"I_name\", \"I_name\", \"O\", \"O\", \"O\", \"O\", \"O\"], [\"B_name\", \"I_name\", \"I_name\", \"I_name\", \"I_name\", \"I_name\", \"I_name\", \"O\", \"O\", \"O\", \"O\", \"O\"], [\"B_film\", \"I_film\", \"I_film\", \"I_film\", \"O\", \"O\", \"O\", \"O\", \"O\"], [\"B_book\", \"I_book\", \"I_book\", \"I_book\", \"I_book\", \"I_book\", \"I_book\", \"I_book\", \"O\", \"O\", \"O\", \"O\", \"O\"], [\"B_name\", \"I_name\", \"I_name\", \"O\", \"O\", \"O\", \"O\", \"O\"], [\"B_book\", \"I_book\", \"I_book\", \"I_book\", \"I_book\", \"I_book\", \"O\", \"O\", \"O\", \"O\"], [\"B_book\", \"I_book\", \"I_book\", \"I_book\", \"I_book\", \"I_book\", \"I_book\", \"O\", \"O\", \"O\", \"O\", \"O\"], [\"B_name\", \"I_name\", \"I_name\", \"I_name\", \"O\", \"O\", \"O\", \"O\", \"O\"], [\"B_book\", \"I_book\", \"I_book\", \"O\", \"O\", \"O\", \"O\", \"O\"]]}'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base64.b64decode(endpoint_output_data).decode('utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monitor SageMaker endpoints\n",
    "\n",
    "There are mainly data quality monitoring and model quality monitoring, in which:\n",
    "\n",
    "- data quality monitoring captures inference input, and compares data statistics like min, max with a baseline created from dataset [[Monitor Data Quality](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-data-quality.html)]\n",
    "- model quality monitoring monitors the performance of a model by comparing the predictions that the model makes with the actual ground truth labels that the model attempts to predict. [[Monitor Model Quality](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-model-quality.html)]\n",
    "\n",
    "Data quality is only applicapable for tabular data, therefore **not suitable** for this question understanding use case. Here we implement a quality monitoring for model quality.\n",
    "\n",
    "Reference:\n",
    "- AWS Doc: [Amazon SageMaker Model Monitor](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor.html)\n",
    "- SageMaker Doc: [Amazon SageMaker Model Monitor](https://sagemaker.readthedocs.io/en/stable/amazon_sagemaker_model_monitoring.html)\n",
    "- [AWS Workshop: Model Monitor](https://sagemaker-immersionday.workshop.aws/lab4/monitoring.html)\n",
    "- [Create a Model Quality Baseline](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-model-quality-baseline.html)\n",
    "\n",
    "### Create a Model Quality Baseline\n",
    "\n",
    "1.  Create an instance of the ModelQualityMonitor class. \n",
    "\n",
    "Check SageMaker ModelQualityMonitor API: [Doc](https://sagemaker.readthedocs.io/en/stable/api/inference/model_monitor.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_output_bucket = 'sm-nlp-data'\n",
    "baseline_job_name = \"QABaseLineJob7\"\n",
    "baseline_job_output_s3 = f\"s3://{baseline_output_bucket}/{baseline_job_name}/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model_monitor import ModelQualityMonitor\n",
    "from sagemaker.model_monitor.dataset_format import DatasetFormat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_quality_monitor = ModelQualityMonitor(\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.4xlarge',\n",
    "    volume_size_in_gb=20,\n",
    "    max_runtime_in_seconds=3600,\n",
    "    sagemaker_session=sess\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Create a baseline dataset in JSON with test data\n",
    "\n",
    "Here we utilize the predicted labels from steps before. This will be compared with ground truth labels to generate baseline job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('processed/test/seq.in') as f:\n",
    "    x_input = f.readlines()\n",
    "    x_input = [x.strip() for x in x_input]\n",
    "with open('processed/test/label') as f:\n",
    "    y_output = f.readlines()\n",
    "    y_output = [y.strip() for y in y_output]\n",
    "with open('processed/test/seq.out') as f:\n",
    "    seq_output = f.readlines()\n",
    "    seq_output = [seq.strip().split() for seq in seq_output]\n",
    "    \n",
    "assert len(predicted_cls) == len(x_input), f\"predicted label should have the same length with input sequence {len(predicted_cls)}!={len(x_input)}\"\n",
    "    \n",
    "test_dataset = {\n",
    "    'seq_in': x_input,\n",
    "    'seq_out': seq_output,\n",
    "    'predicted_label': predicted_cls,\n",
    "    'label': y_output\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq_in</th>\n",
       "      <th>seq_out</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>伊坂幸太郎写了哪些书</td>\n",
       "      <td>[B_name, I_name, I_name, I_name, I_name, O, O,...</td>\n",
       "      <td>ask_books</td>\n",
       "      <td>ask_books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ONE PIECE総集编 THE FIRST LOG是谁写的</td>\n",
       "      <td>[B_book, I_book, I_book, I_book, I_book, I_boo...</td>\n",
       "      <td>ask_author</td>\n",
       "      <td>ask_author</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>高效管理Windows网络/Win32 Perl应用之道的作者是谁</td>\n",
       "      <td>[B_book, I_book, I_book, I_book, I_book, I_boo...</td>\n",
       "      <td>ask_author</td>\n",
       "      <td>ask_author</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dave写了什么书</td>\n",
       "      <td>[B_name, I_name, I_name, I_name, O, O, O, O, O]</td>\n",
       "      <td>ask_books</td>\n",
       "      <td>ask_books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>洪荒之武道是谁写的</td>\n",
       "      <td>[B_book, I_book, I_book, I_book, I_book, O, O,...</td>\n",
       "      <td>ask_author</td>\n",
       "      <td>ask_author</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>有哪些人从深圳大学毕业</td>\n",
       "      <td>[O, O, O, O, O, B_school, I_school, I_school, ...</td>\n",
       "      <td>ask_alumni</td>\n",
       "      <td>ask_alumni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>烈火如歌的导演是谁</td>\n",
       "      <td>[B_film, I_film, I_film, I_film, O, O, O, O, O]</td>\n",
       "      <td>ask_director</td>\n",
       "      <td>ask_director</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>烈火如歌的导演是谁</td>\n",
       "      <td>[B_film, I_film, I_film, I_film, O, O, O, O, O]</td>\n",
       "      <td>ask_director</td>\n",
       "      <td>ask_director</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>梁胜权导演了哪些电视剧</td>\n",
       "      <td>[B_name, I_name, I_name, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>ask_films</td>\n",
       "      <td>ask_films</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>于梦然的国籍是什么</td>\n",
       "      <td>[B_name, I_name, I_name, O, O, O, O, O, O]</td>\n",
       "      <td>ask_nationality</td>\n",
       "      <td>ask_nationality</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>358 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                seq_in  \\\n",
       "0                           伊坂幸太郎写了哪些书   \n",
       "1       ONE PIECE総集编 THE FIRST LOG是谁写的   \n",
       "2    高效管理Windows网络/Win32 Perl应用之道的作者是谁   \n",
       "3                            Dave写了什么书   \n",
       "4                            洪荒之武道是谁写的   \n",
       "..                                 ...   \n",
       "353                        有哪些人从深圳大学毕业   \n",
       "354                          烈火如歌的导演是谁   \n",
       "355                          烈火如歌的导演是谁   \n",
       "356                        梁胜权导演了哪些电视剧   \n",
       "357                          于梦然的国籍是什么   \n",
       "\n",
       "                                               seq_out  predicted_label  \\\n",
       "0    [B_name, I_name, I_name, I_name, I_name, O, O,...        ask_books   \n",
       "1    [B_book, I_book, I_book, I_book, I_book, I_boo...       ask_author   \n",
       "2    [B_book, I_book, I_book, I_book, I_book, I_boo...       ask_author   \n",
       "3      [B_name, I_name, I_name, I_name, O, O, O, O, O]        ask_books   \n",
       "4    [B_book, I_book, I_book, I_book, I_book, O, O,...       ask_author   \n",
       "..                                                 ...              ...   \n",
       "353  [O, O, O, O, O, B_school, I_school, I_school, ...       ask_alumni   \n",
       "354    [B_film, I_film, I_film, I_film, O, O, O, O, O]     ask_director   \n",
       "355    [B_film, I_film, I_film, I_film, O, O, O, O, O]     ask_director   \n",
       "356   [B_name, I_name, I_name, O, O, O, O, O, O, O, O]        ask_films   \n",
       "357         [B_name, I_name, I_name, O, O, O, O, O, O]  ask_nationality   \n",
       "\n",
       "               label  \n",
       "0          ask_books  \n",
       "1         ask_author  \n",
       "2         ask_author  \n",
       "3          ask_books  \n",
       "4         ask_author  \n",
       "..               ...  \n",
       "353       ask_alumni  \n",
       "354     ask_director  \n",
       "355     ask_director  \n",
       "356        ask_films  \n",
       "357  ask_nationality  \n",
       "\n",
       "[358 rows x 4 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "test_frame = pd.DataFrame(test_dataset)\n",
    "test_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 336\n",
      "Wrong: 22\n",
      "Acc: 0.9385474860335196\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "wrong = 0\n",
    "for x, y in zip(predicted_cls, y_output):\n",
    "    if x != y:\n",
    "        wrong += 1\n",
    "    else:\n",
    "        correct += 1\n",
    "print(f\"Correct: {correct}\")\n",
    "print(f\"Wrong: {wrong}\")\n",
    "print(f\"Acc: {correct/len(predicted_cls)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`suggest_baseline` works better with lines records, so we convert DataFrame to jsonlines file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_frame.to_json(path_or_buf='test_dataset.json', orient='records', lines=True, force_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deprecated method, convert by hand:\n",
    "```python\n",
    "with open('test_dataset1.jsonl', 'w') as f:\n",
    "    for seq_in, seq_out, predicted_label, label in zip(test_dataset['seq_in'], \\\n",
    "        test_dataset['seq_out'], test_dataset['predicted_label'], test_dataset['label']):\n",
    "        json.dump({'seq_in': seq_in, 'seq_out': seq_out, 'predicted_label': predicted_label, \\\n",
    "            'label': label}, f, ensure_ascii=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Now call the suggest_baseline method of the ModelQualityMonitor object to run a baseline job. We need a baseline dataset that contains both predictions and labels stored in Amazon S3.</br> \n",
    "Suggest baseline specification: [ModelQualityMonitor.suggest_baseline](https://sagemaker.readthedocs.io/en/stable/api/inference/model_monitor.html#sagemaker.model_monitor.model_monitoring.ModelQualityMonitor.suggest_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Name:  QABaseLineJob7\n",
      "Inputs:  [{'InputName': 'baseline_dataset_input', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-093729152554/model-monitor/baselining/QABaseLineJob7/input/baseline_dataset_input', 'LocalPath': '/opt/ml/processing/input/baseline_dataset_input', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
      "Outputs:  [{'OutputName': 'monitoring_output', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sm-nlp-data/QABaseLineJob7/', 'LocalPath': '/opt/ml/processing/output', 'S3UploadMode': 'EndOfJob'}}]\n"
     ]
    }
   ],
   "source": [
    "job = model_quality_monitor.suggest_baseline(\n",
    "    job_name=baseline_job_name,\n",
    "    baseline_dataset='./test_dataset.json', # The S3 location of the validation dataset.\n",
    "    dataset_format=DatasetFormat.json(lines=True), # Whether the file should be read as a json object per line\n",
    "    output_s3_uri=baseline_job_output_s3, # The S3 location to store the results.\n",
    "    problem_type='MulticlassClassification',\n",
    "    inference_attribute= \"predicted_label\", # The column in the dataset that contains predictions.\n",
    "    ground_truth_attribute= \"label\" # The column in the dataset that contains ground truth labels.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job.wait(logs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the baseline job finishes, you can see the constraints that the job generated. First, get the results of the baseline job by calling the `latest_baselining_job` method of the ModelQualityMonitor object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_job = model_quality_monitor.latest_baselining_job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The baseline job suggests constraints, which are thresholds for metrics that model monitor measures. If a metric goes beyond the suggested threshold, Model Monitor reports a violation. To view the constraints that the baseline job generated, call the suggested_constraints method of the baseline job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>comparison_operator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.938547</td>\n",
       "      <td>LessThanThreshold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted_recall</th>\n",
       "      <td>0.938547</td>\n",
       "      <td>LessThanThreshold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted_precision</th>\n",
       "      <td>0.939565</td>\n",
       "      <td>LessThanThreshold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted_f0_5</th>\n",
       "      <td>0.939081</td>\n",
       "      <td>LessThanThreshold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted_f1</th>\n",
       "      <td>0.938622</td>\n",
       "      <td>LessThanThreshold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted_f2</th>\n",
       "      <td>0.938475</td>\n",
       "      <td>LessThanThreshold</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   threshold comparison_operator\n",
       "accuracy            0.938547   LessThanThreshold\n",
       "weighted_recall     0.938547   LessThanThreshold\n",
       "weighted_precision  0.939565   LessThanThreshold\n",
       "weighted_f0_5       0.939081   LessThanThreshold\n",
       "weighted_f1         0.938622   LessThanThreshold\n",
       "weighted_f2         0.938475   LessThanThreshold"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(baseline_job.suggested_constraints().body_dict['multiclass_classification_constraints']).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schedule Model Quality Monitoring Jobs \n",
    "\n",
    "You can create a model monitoring schedule for the endpoint created earlier. Use the baseline resources (constraints and statistics) to compare against the real-time traffic. \n",
    "\n",
    "Check Amazon docs for setting up a scheduled monitor quality check: [Schedule Model Quality Monitoring Jobs ](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-model-quality-schedule.html)\n",
    "\n",
    "API definition for `create_model_quality_job_definition`: [create_model_quality_job_definition](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sagemaker.html#SageMaker.Client.create_model_quality_job_definition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy over the training dataset to Amazon S3 (if you already have it in Amazon S3, you could reuse it)\n",
    "baseline_prefix = prefix + '/baselining'\n",
    "baseline_data_prefix = baseline_prefix + '/data'\n",
    "baseline_results_prefix = baseline_prefix + '/results'\n",
    "\n",
    "baseline_data_uri = 's3://{}/{}'.format(bucket,baseline_data_prefix)\n",
    "baseline_results_uri = 's3://{}/{}'.format(bucket, baseline_results_prefix)\n",
    "print('Baseline data uri: {}'.format(baseline_data_uri))\n",
    "print('Baseline results uri: {}'.format(baseline_results_uri))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_file = open(\"test_data/training-dataset-with-header.csv\", 'rb')\n",
    "s3_key = os.path.join(baseline_prefix, 'data', 'training-dataset-with-header.csv')\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(s3_key).upload_fileobj(training_data_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a model monitoring schedule for the endpoint using the baseline constraints and statistics to compare against real-time traffic. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sm-nlp-data/QABaseLineJob6/output'"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3_report_path = f\"s3://{baseline_output_bucket}/{baseline_job_name}/output\"\n",
    "s3_report_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method create_monitoring_schedule in module sagemaker.model_monitor.model_monitoring:\n",
      "\n",
      "create_monitoring_schedule(endpoint_input, ground_truth_input, problem_type, record_preprocessor_script=None, post_analytics_processor_script=None, output_s3_uri=None, constraints=None, monitor_schedule_name=None, schedule_cron_expression=None, enable_cloudwatch_metrics=True) method of sagemaker.model_monitor.model_monitoring.ModelQualityMonitor instance\n",
      "    Creates a monitoring schedule.\n",
      "    \n",
      "    Args:\n",
      "        endpoint_input (str or sagemaker.model_monitor.EndpointInput): The endpoint to\n",
      "            monitor. This can either be the endpoint name or an EndpointInput.\n",
      "        ground_truth_input (str): S3 URI to ground truth dataset.\n",
      "        problem_type (str): The type of problem of this model quality monitoring. Valid\n",
      "            values are \"Regression\", \"BinaryClassification\", \"MulticlassClassification\".\n",
      "        record_preprocessor_script (str): The path to the record preprocessor script. This can\n",
      "            be a local path or an S3 uri.\n",
      "        post_analytics_processor_script (str): The path to the record post-analytics processor\n",
      "            script. This can be a local path or an S3 uri.\n",
      "        output_s3_uri (str): S3 destination of the constraint_violations and analysis result.\n",
      "            Default: \"s3://<default_session_bucket>/<job_name>/output\"\n",
      "        constraints (sagemaker.model_monitor.Constraints or str): If provided it will be used\n",
      "            for monitoring the endpoint. It can be a Constraints object or an S3 uri pointing\n",
      "            to a constraints JSON file.\n",
      "        monitor_schedule_name (str): Schedule name. If not specified, the processor generates\n",
      "            a default job name, based on the image name and current timestamp.\n",
      "        schedule_cron_expression (str): The cron expression that dictates the frequency that\n",
      "            this job run. See sagemaker.model_monitor.CronExpressionGenerator for valid\n",
      "            expressions. Default: Daily.\n",
      "        enable_cloudwatch_metrics (bool): Whether to publish cloudwatch metrics as part of\n",
      "            the baselining or monitoring jobs.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(model_quality_monitor.create_monitoring_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model_monitor import CronExpressionGenerator\n",
    "from time import gmtime, strftime\n",
    "\n",
    "mon_schedule_name = 'qa-model-monitor-schedule-' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "model_quality_monitor.create_monitoring_schedule(\n",
    "    monitor_schedule_name=mon_schedule_name,\n",
    "    endpoint_input=predictor.endpoint,\n",
    "    output_s3_uri=s3_report_path,\n",
    "    problem_type='MulticlassClassification',\n",
    "    constraints=model_quality_monitor.suggested_constraints(),\n",
    "    ground_truth_input=？？？\n",
    "    schedule_cron_expression=CronExpressionGenerator.daily(),\n",
    "    enable_cloudwatch_metrics=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "model_quality_job_definition_name = f\"qa-model-quality-definition-{int(time.time())}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker.create_model_quality_job_definition(\n",
    "    JobDefinitionName=model_quality_job_definition_name,\n",
    "    ModelQualityBaselineConfig={\n",
    "        'BaseliningJobName': baseline_job_name,\n",
    "        'ConstraintsResource': {\n",
    "            'S3Uri': baseline_job_output_s3\n",
    "        },\n",
    "        ModelQualityAppSpecification={\n",
    "            'ImageUri': 'string',\n",
    "            'ContainerEntrypoint': [\n",
    "                'string',\n",
    "            ],\n",
    "            'ContainerArguments': [\n",
    "                'string',\n",
    "            ],\n",
    "            'RecordPreprocessorSourceUri': 'string',\n",
    "            'PostAnalyticsProcessorSourceUri': 'string',\n",
    "            'ProblemType': 'BinaryClassification'|'MulticlassClassification'|'Regression',\n",
    "            'Environment': {\n",
    "                'string': 'string'\n",
    "            }\n",
    "        },\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['JOB_DEFINITION_BASE_NAME',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_attach',\n",
       " '_build_create_model_quality_job_definition_request',\n",
       " '_create_monitoring_schedule_from_job_definition',\n",
       " '_generate_baselining_job_name',\n",
       " '_generate_env_map',\n",
       " '_generate_monitoring_schedule_name',\n",
       " '_get_baseline_files',\n",
       " '_get_default_image_uri',\n",
       " '_normalize_baseline_inputs',\n",
       " '_normalize_baseline_output',\n",
       " '_normalize_endpoint_input',\n",
       " '_normalize_monitoring_output',\n",
       " '_normalize_monitoring_output_fields',\n",
       " '_normalize_processing_output',\n",
       " '_s3_uri_from_local_path',\n",
       " '_update_monitoring_schedule',\n",
       " '_upload_and_convert_to_processing_input',\n",
       " '_validate_network_config',\n",
       " '_wait_for_schedule_changes_to_apply',\n",
       " 'arguments',\n",
       " 'attach',\n",
       " 'base_job_name',\n",
       " 'baseline_statistics',\n",
       " 'baselining_jobs',\n",
       " 'create_monitoring_schedule',\n",
       " 'delete_monitoring_schedule',\n",
       " 'describe_latest_baselining_job',\n",
       " 'describe_schedule',\n",
       " 'entrypoint',\n",
       " 'env',\n",
       " 'image_uri',\n",
       " 'instance_count',\n",
       " 'instance_type',\n",
       " 'job_definition_name',\n",
       " 'latest_baselining_job',\n",
       " 'latest_baselining_job_name',\n",
       " 'latest_monitoring_constraint_violations',\n",
       " 'latest_monitoring_statistics',\n",
       " 'list_executions',\n",
       " 'max_runtime_in_seconds',\n",
       " 'monitoring_schedule_name',\n",
       " 'monitoring_type',\n",
       " 'network_config',\n",
       " 'output_kms_key',\n",
       " 'role',\n",
       " 'run_baseline',\n",
       " 'sagemaker_session',\n",
       " 'start_monitoring_schedule',\n",
       " 'stop_monitoring_schedule',\n",
       " 'suggest_baseline',\n",
       " 'suggested_constraints',\n",
       " 'tags',\n",
       " 'update_monitoring_schedule',\n",
       " 'volume_kms_key',\n",
       " 'volume_size_in_gb']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(model_quality_monitor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe and inspect the schedule: After you describe it, observe that the MonitoringScheduleStatus in MonitoringScheduleSummary returned by the ListMonitoringSchedules API changes to Scheduled. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_schedule_result = my_default_monitor.describe_schedule()\n",
    "print('Schedule status: {}'.format(desc_schedule_result['MonitoringScheduleStatus']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ingest Ground Truth Labels and Merge Them With Predictions\n",
    "\n",
    "Model quality monitoring compares the predictions your model makes with ground truth labels to measure the quality of the model. For this to work, you periodically label data captured by your endpoint and upload it to Amazon S3.\n",
    "\n",
    "Check this doc: [Ingest Ground Truth Labels and Merge Them With Predictions](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-model-quality-merge.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.6 Python 3.6 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/pytorch-1.6-gpu-py36-cu110-ubuntu18.04-v3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
